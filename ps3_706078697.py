# -*- coding: utf-8 -*-
"""PS3_706078697.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QQM_axzBcl1-ENRdwJcv5rHS1mCkqMdU
"""

import pandas as pd
import numpy as np
from datetime import datetime

# Read the data from the CSV file
df = pd.read_csv('CRSP_Stocks.csv')

# Convert date column to datetime type
df['date'] = pd.to_datetime(df['date'])

# Filter data for years 1927-2022
df = df[df['date'].dt.year.between(1927, 2022)]

# Convert 'PRC' column to numeric
df['PRC'] = pd.to_numeric(df['PRC'], errors='coerce')

# Convert 'DLRET' column to numeric
df['DLRET'] = pd.to_numeric(df['DLRET'], errors='coerce')

# Convert 'RET' column to numeric
df['RET'] = pd.to_numeric(df['RET'], errors='coerce')

# Create 'Year' and 'Month' columns
df['Year'] = df['date'].dt.year
df['Month'] = df['date'].dt.month

# Calculate lagged market capitalization
df['lag_Mkt_Cap'] = df.groupby('PERMNO')['PRC'].shift()

# Calculate ranking returns
df['Ranking_Ret'] = df.groupby(['Year', 'Month'])['RET'].rank(ascending=False)

# Select required columns
CRSP_Stocks_Momentum = df[['PERMNO', 'Year', 'Month', 'EXCHCD', 'lag_Mkt_Cap', 'RET', 'Ranking_Ret']]

# Format the returns as decimal proportion
CRSP_Stocks_Momentum['RET'] = CRSP_Stocks_Momentum['RET'] / 100

# Display the resulting dataframe
print(CRSP_Stocks_Momentum)

def PS3_Q2(df):
    # Create a copy of the input dataframe
    df = df.copy()

    # Drop rows with missing values
    df = df.dropna()

    # Convert columns to numeric
    df['Ranking_Ret'] = pd.to_numeric(df['Ranking_Ret'], errors='coerce')
    df['lag_Mkt_Cap'] = pd.to_numeric(df['lag_Mkt_Cap'], errors='coerce')

    # Calculate the momentum deciles based on Daniel and Moskowitz (DM) method
    df['DM_decile'] = df.groupby(['Year', 'Month'])['Ranking_Ret'].transform(lambda x: pd.qcut(x, 10, labels=False, duplicates='drop') + 1)

    # Calculate the momentum deciles based on Kenneth R. French (KRF) method
    df['KRF_decile'] = df.groupby(['Year', 'Month'])['lag_Mkt_Cap'].transform(lambda x: pd.qcut(x, 10, labels=False, duplicates='drop') + 1)

    # Select the desired columns
    df = df[['Year', 'Month', 'PERMNO', 'lag_Mkt_Cap', 'RET', 'DM_decile', 'KRF_decile']]

    # Format the returns as decimal proportion
    df['RET'] = df['RET'] / 100

    # Return the resulting dataframe
    return df

FF_mkt = df.copy()

CRSP_Stocks_Momentum_decile = PS3_Q2(CRSP_Stocks_Momentum)
print(CRSP_Stocks_Momentum_decile)

crsp_stocks = pd.read_csv('CRSP_Stocks2.csv')

def calculate_stock_returns(crsp_stocks):


    # Filter out unwanted samples
    restricted_universe = crsp_stocks[(crsp_stocks['shrcd'].isin([10, 11])) & 
                                      (crsp_stocks['exchcd'].isin([1, 2, 3]))]

    # Clean data, first round
    cleaned_first_round = restricted_universe.copy()
    cleaned_first_round['date'] = pd.to_datetime(cleaned_first_round['date'], format='%Y-%m-%d')
    cleaned_first_round['adj_price'] = abs(cleaned_first_round['prc'])
    cleaned_first_round['market_cap'] = cleaned_first_round['adj_price'] * cleaned_first_round['shrout']
    cleaned_first_round['adj_return'] = pd.to_numeric(cleaned_first_round['ret'], errors='coerce')
    cleaned_first_round['adj_dlreturn'] = pd.to_numeric(cleaned_first_round['dlret'], errors='coerce')

    # Clean data, second round
    cleaned_second_round = cleaned_first_round[(cleaned_first_round['adj_price'] > 0) & 
                                                (cleaned_first_round['shrout'] > 0) & 
                                                (cleaned_first_round['adj_return'].notna() | 
                                                 cleaned_first_round['adj_dlreturn'].notna())].copy()
    cleaned_second_round['return'] = cleaned_second_round.apply(lambda row: 
                                                                (1 + row['adj_return']) * 
                                                                (1 + row['adj_dlreturn']) - 1 if 
                                                                row['adj_return'] and 
                                                                row['adj_dlreturn'] else 
                                                                row['adj_return'] or 
                                                                row['adj_dlreturn'], axis=1)
    cleaned_second_round['year'] = cleaned_second_round['date'].dt.year
    cleaned_second_round['month'] = cleaned_second_round['date'].dt.month
    cleaned_second_round['lag_market_cap'] = cleaned_second_round.groupby('permno')['market_cap'].shift()

    # Calculate stock returns and group into year, month
    cleaned_shifted_df = cleaned_second_round.loc[cleaned_second_round['lag_market_cap'].notna()].copy()
    cleaned_shifted_df['weighted_return'] = cleaned_shifted_df['return'] * cleaned_shifted_df['lag_market_cap']
    stock_lag_mv = cleaned_shifted_df.groupby(['year', 'month'])['lag_market_cap'].sum().reset_index()
    stock_vw_ret = cleaned_shifted_df.groupby(['year', 'month'])['weighted_return'].sum().reset_index()

    stock_ew_ret = cleaned_shifted_df.groupby(['year', 'month'])['return'].mean().reset_index()


    # Generate output
    result = pd.merge(stock_lag_mv, stock_vw_ret, on=['year', 'month'], how='outer')
    result = pd.merge(result, stock_ew_ret, on=['year', 'month'], how='outer')
    result['vw_return'] = result['weighted_return'] / result['lag_market_cap']
    output = result[['year', 'month', 'lag_market_cap', 'return', 'vw_return']].copy()
    output.columns = ['Year', 'Month', 'Stock_lag_MV', 'Stock_Ew_Ret', 'Stock_Vw_Ret']
    return output

# Call the function and pass the DataFrame as an argument
output = calculate_stock_returns(crsp_stocks)
output = output.drop(index=[0, 1, 2, 3, 4, 5])
output["date"] = output["Year"] * 100 + output["Month"]

ff_df=pd.read_csv('F-F_Research_Data_Factors.CSV',skiprows=3,nrows=1158)
ff_df.columns=['date','Mkt-RF', 'SMB', 'HML', 'RF']
merged_df = pd.merge(output,ff_df,on='date')
#Converting % to decimal
merged_df['Stock_Vw_Ret']=100*merged_df['Stock_Vw_Ret']
#Calculating Excess Return
merged_df["Estimated_Mkt-RF"]=merged_df['Stock_Vw_Ret']-merged_df['RF']
df = merged_df[['Estimated_Mkt-RF','Mkt-RF']]
annual_rf = merged_df['RF'].mean()*12
# annualized mean
annualized_mean = df.mean() * 12
# annualized standard deviation
annualized_std = df.std() * np.sqrt(12)
# annualized Sharpe Ratio
annualized_sharpe_ratio = (annualized_mean - annual_rf) / annualized_std
# skewness
skewness = df.skew()
# excess kurtosis
excess_kurtosis = df.kurtosis() - 3

rows = ['Annualized Mean', 'Annualized Standard Deviation', 'Annualized Sharpe Ratio', 'Skewness', 'Excess Kurtosis']
df_matrix = pd.DataFrame([annualized_mean, annualized_std, annualized_sharpe_ratio, skewness, excess_kurtosis], index=rows)
df_matrix.columns=['Estimated FF Market Excess Return',' Actual FF Market Excess Return']
ff_df

ff_df['date']

# Extract the Year and Month from the date column in ff_df
ff_df['Year'] = ff_df['date'] // 100
ff_df['Month'] = ff_df['date'] % 100

# Display the updated dataframe
print(ff_df)

# Merge the two dataframes based on 'Year' and 'Month' columns
merged_df = CRSP_Stocks_Momentum_decile.merge(ff_df, on=['Year', 'Month'])

# Create or rename the desired columns
merged_df.rename(columns={'DM_decile': 'decile'}, inplace=True)
merged_df.rename(columns={'RET': 'DM Ret'}, inplace=True)
merged_df.rename(columns={'KRF_decile': 'KRF Ret'}, inplace=True)

# Select the desired columns
CRSP_Stocks_Momentum_returns = merged_df[['Year', 'Month', 'decile', 'DM Ret', 'KRF Ret', 'RF']]

# Reset the index
CRSP_Stocks_Momentum_returns.reset_index(drop=True, inplace=True)

# Display the resulting dataframe
print(CRSP_Stocks_Momentum_returns)

def PS3_Q4(df):
    # Calculate the average excess return (r - rf) for each decile
    avg_excess_return = df.groupby('decile')['DM Ret'].mean() - df['RF'].mean()

    # Calculate the standard deviation of excess return for each decile
    std_excess_return = df.groupby('decile')['DM Ret'].std()

    # Calculate the Sharpe ratio for each decile
    sharpe_ratio = avg_excess_return / std_excess_return

    # Calculate the skewness of monthly returns for each decile
    skewness = df.groupby('decile')['DM Ret'].apply(lambda x: x.skew())

    # Calculate the WML (Winner minus Loser) spread
    wml = avg_excess_return.iloc[-1] - avg_excess_return.iloc[0]

    # Create a dataframe to store the results
    table1 = pd.DataFrame({
        'Decile 1': [avg_excess_return.iloc[0], std_excess_return.iloc[0], sharpe_ratio.iloc[0], skewness.iloc[0]],
        'Decile 2': [avg_excess_return.iloc[1], std_excess_return.iloc[1], sharpe_ratio.iloc[1], skewness.iloc[1]],
        'Decile 3': [avg_excess_return.iloc[2], std_excess_return.iloc[2], sharpe_ratio.iloc[2], skewness.iloc[2]],
        'Decile 4': [avg_excess_return.iloc[3], std_excess_return.iloc[3], sharpe_ratio.iloc[3], skewness.iloc[3]],
        'Decile 5': [avg_excess_return.iloc[4], std_excess_return.iloc[4], sharpe_ratio.iloc[4], skewness.iloc[4]],
        'Decile 6': [avg_excess_return.iloc[5], std_excess_return.iloc[5], sharpe_ratio.iloc[5], skewness.iloc[5]],
        'Decile 7': [avg_excess_return.iloc[6], std_excess_return.iloc[6], sharpe_ratio.iloc[6], skewness.iloc[6]],
        'Decile 8': [avg_excess_return.iloc[7], std_excess_return.iloc[7], sharpe_ratio.iloc[7], skewness.iloc[7]],
        'Decile 9': [avg_excess_return.iloc[8], std_excess_return.iloc[8], sharpe_ratio.iloc[8], skewness.iloc[8]],
        'Decile 10': [avg_excess_return.iloc[9], std_excess_return.iloc[9], sharpe_ratio.iloc[9], skewness.iloc[9]],
        'WML': [wml, np.nan, np.nan, np.nan]
    }, index=['Avg Excess Return', 'Standard Deviation', 'Sharpe Ratio', 'Skewness'])

    # Return the resulting dataframe
    return table1

output_table = PS3_Q4(CRSP_Stocks_Momentum_returns)
print(output_table)

# Read the DM_returns.txt file
DM_returns = pd.read_csv('DM_returns.txt', sep='\s+', header=None,
                         names=['Date', 'decile', 'Ret', 'a', 'b'])

# Print the DataFrame
print(DM_returns)

# Convert the "Date" column to datetime format
DM_returns['Date'] = pd.to_datetime(DM_returns['Date'], format='%Y%m%d')

# Extract the "Year" and "Month" information
DM_returns['Year'] = DM_returns['Date'].dt.year
DM_returns['Month'] = DM_returns['Date'].dt.month

# Display the modified DataFrame
print(DM_returns)

KRF_returns = pd.read_csv('KRF_returns.CSV', delimiter='\t', skiprows=10)
# Display the DataFrame
print(KRF_returns)

DM_returns['Ret'] *= 100

# Calculate the correlations
correlation_DM = DM_returns['Ret'].corr(CRSP_Stocks_Momentum_returns['DM Ret'])
correlation_KRF = DM_returns['Ret'].corr(CRSP_Stocks_Momentum_returns['KRF Ret'])

# Round the correlations to 4 decimal places
correlation_DM = round(correlation_DM, 4)
correlation_KRF = round(correlation_KRF, 4)

# Create the output matrix/dataframe
output_df = pd.DataFrame({'DM Momentum Portfolio Correlation': [correlation_DM],
                          'KRF Momentum Portfolio Correlation': [correlation_KRF]})

# Initialize a dictionary to store the correlations for each decile
correlations = {}

# Iterate over the deciles
for decile in range(1, 11):
    # Filter the data for the current decile
    DM_decile = DM_returns[DM_returns['decile'] == decile]
    CRSP_decile = CRSP_Stocks_Momentum_returns[CRSP_Stocks_Momentum_returns['decile'] == decile]

    # Calculate the correlation for the current decile
    correlation_DM = DM_decile['Ret'].corr(CRSP_decile['DM Ret'])
    correlation_KRF = DM_decile['Ret'].corr(CRSP_decile['KRF Ret'])

    # Round the correlations to 4 decimal places and store them in the dictionary
    correlations[f'Decile {decile}'] = {'DM Momentum Portfolio Correlation': round(correlation_DM, 4),
                                        'KRF Momentum Portfolio Correlation': round(correlation_KRF, 4)}

# Create a dataframe from the correlations dictionary
output_df = pd.DataFrame.from_dict(correlations, orient='index')